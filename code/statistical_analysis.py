"""
åŸºçº¿å¯¹æ¯”å®éªŒ - ç»Ÿè®¡åˆ†æè„šæœ¬
=============================

åŠŸèƒ½: åˆ†æ96ä¸ªå›æµ‹ç»“æœ,ç”Ÿæˆç»Ÿè®¡æ£€éªŒæŠ¥å‘Š
ä½œè€…: Claude Code AI Assistant
æ—¥æœŸ: 2025-11-27
Python: 3.8+

åˆ†æå†…å®¹:
1. é…å¯¹tæ£€éªŒ (Paired t-test): LLM vs æ¯ä¸ªåŸºçº¿
2. å¯¹æ¯”è¡¨æ ¼ç”Ÿæˆ
3. æ˜¾è‘—æ€§åˆ†æ
4. å¯è§†åŒ–å›¾è¡¨

è¾“å…¥: baseline_comparison_results.json (ç”±test_all_baselines.pyç”Ÿæˆ)
è¾“å‡º: ç»Ÿè®¡æ£€éªŒæŠ¥å‘Š(Markdown) + å›¾è¡¨(PNG)
"""

import json
import numpy as np
import pandas as pd
from scipy import stats
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import sys

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']  # ä¸­æ–‡å­—ä½“
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜


# =============================================================================
# æ•°æ®åŠ è½½
# =============================================================================

def load_results(json_path):
    """
    åŠ è½½å®éªŒç»“æœJSONæ–‡ä»¶

    Args:
        json_path: JSONæ–‡ä»¶è·¯å¾„

    Returns:
        dict: å®Œæ•´çš„å®éªŒç»“æœ
    """
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"âœ… æˆåŠŸåŠ è½½ç»“æœæ–‡ä»¶: {json_path}")
        print(f"   ç­–ç•¥æ•°: {len(data['results'])}")
        print(f"   å…ƒæ•°æ®: {data.get('metadata', {}).get('timestamp', 'N/A')}")
        return data
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æå¤±è´¥: {e}")
        sys.exit(1)


# =============================================================================
# é…å¯¹tæ£€éªŒ
# =============================================================================

def paired_t_test(results_dict, baseline_name, ours_name='LLM_Adaptive',
                  period='training_period', metric='returns_pct'):
    """
    å¯¹ä¸¤ä¸ªç­–ç•¥è¿›è¡Œé…å¯¹tæ£€éªŒ

    Args:
        results_dict: å®Œæ•´ç»“æœå­—å…¸
        baseline_name: åŸºçº¿ç­–ç•¥åç§° (e.g., 'Buy_and_Hold')
        ours_name: æˆ‘ä»¬çš„ç­–ç•¥åç§° (default: 'LLM_Adaptive')
        period: 'training_period' æˆ– 'testing_period'
        metric: è¦æ¯”è¾ƒçš„æŒ‡æ ‡ (default: 'returns_pct')

    Returns:
        dict: åŒ…å«tç»Ÿè®¡é‡ã€på€¼ã€å‡å€¼å·®å¼‚ç­‰
    """
    baseline_values = []
    ours_values = []
    assets = []

    # æå–æ‰€æœ‰èµ„äº§çš„æŒ‡æ ‡å€¼
    for asset_name in results_dict[baseline_name].keys():
        baseline_result = results_dict[baseline_name][asset_name][period]
        ours_result = results_dict[ours_name][asset_name][period]

        # è·³è¿‡å¤±è´¥çš„å›æµ‹ (None)
        if baseline_result is None or ours_result is None:
            continue

        baseline_val = baseline_result[metric]
        ours_val = ours_result[metric]

        baseline_values.append(baseline_val)
        ours_values.append(ours_val)
        assets.append(asset_name)

    if len(baseline_values) == 0:
        return None

    baseline_values = np.array(baseline_values)
    ours_values = np.array(ours_values)

    # é…å¯¹tæ£€éªŒ
    t_stat, p_value = stats.ttest_rel(ours_values, baseline_values)

    # è®¡ç®—å·®å¼‚
    differences = ours_values - baseline_values
    mean_diff = np.mean(differences)
    std_diff = np.std(differences, ddof=1)

    # è®¡ç®—å‡å€¼
    baseline_mean = np.mean(baseline_values)
    ours_mean = np.mean(ours_values)

    # è®¡ç®—æˆåŠŸç‡ (æ”¶ç›Š>0çš„èµ„äº§æ¯”ä¾‹)
    baseline_success_rate = np.sum(baseline_values > 0) / len(baseline_values) * 100
    ours_success_rate = np.sum(ours_values > 0) / len(ours_values) * 100

    # åˆ¤å®šæ˜¾è‘—æ€§
    if p_value < 0.01:
        significance = 'Highly Significant (p<0.01)'
        sig_level = 'â­â­â­'
    elif p_value < 0.05:
        significance = 'Significant (p<0.05)'
        sig_level = 'â­â­'
    elif p_value < 0.10:
        significance = 'Marginally Significant (p<0.10)'
        sig_level = 'â­'
    else:
        significance = 'Not Significant (pâ‰¥0.10)'
        sig_level = 'âŒ'

    return {
        't_statistic': t_stat,
        'p_value': p_value,
        'mean_difference': mean_diff,
        'std_difference': std_diff,
        'baseline_mean': baseline_mean,
        'ours_mean': ours_mean,
        'baseline_success_rate': baseline_success_rate,
        'ours_success_rate': ours_success_rate,
        'sample_size': len(baseline_values),
        'significance': significance,
        'sig_level': sig_level,
        'assets': assets,
        'baseline_values': baseline_values.tolist(),
        'ours_values': ours_values.tolist(),
        'differences': differences.tolist()
    }


# =============================================================================
# å¯¹æ¯”è¡¨æ ¼ç”Ÿæˆ
# =============================================================================

def generate_comparison_table(results_dict, period='training_period',
                               metric='returns_pct'):
    """
    ç”Ÿæˆå®Œæ•´å¯¹æ¯”è¡¨æ ¼

    Args:
        results_dict: å®Œæ•´ç»“æœå­—å…¸
        period: 'training_period' æˆ– 'testing_period'
        metric: è¦æ˜¾ç¤ºçš„æŒ‡æ ‡

    Returns:
        pd.DataFrame: å¯¹æ¯”è¡¨æ ¼
    """
    strategies = list(results_dict.keys())
    assets = list(results_dict[strategies[0]].keys())

    # åˆ›å»ºDataFrame
    rows = []
    for asset in assets:
        row = {'Asset': asset}
        for strategy in strategies:
            result = results_dict[strategy][asset][period]
            if result is None:
                row[strategy] = 'FAILED'
            else:
                value = result[metric]
                if metric == 'returns_pct':
                    row[strategy] = f"{value:+.2f}%"
                elif metric == 'sharpe_ratio':
                    row[strategy] = f"{value:.3f}"
                elif metric == 'max_drawdown_pct':
                    row[strategy] = f"{value:.2f}%"
                else:
                    row[strategy] = str(value)
        rows.append(row)

    # æ·»åŠ å¹³å‡å€¼è¡Œ
    avg_row = {'Asset': '**Average**'}
    for strategy in strategies:
        values = []
        for asset in assets:
            result = results_dict[strategy][asset][period]
            if result is not None:
                values.append(result[metric])
        if values:
            avg_val = np.mean(values)
            if metric == 'returns_pct':
                avg_row[strategy] = f"**{avg_val:+.2f}%**"
            elif metric == 'sharpe_ratio':
                avg_row[strategy] = f"**{avg_val:.3f}**"
            elif metric == 'max_drawdown_pct':
                avg_row[strategy] = f"**{avg_val:.2f}%**"
            else:
                avg_row[strategy] = f"**{avg_val:.1f}**"
        else:
            avg_row[strategy] = 'N/A'
    rows.append(avg_row)

    # æ·»åŠ æˆåŠŸç‡è¡Œ
    success_row = {'Asset': '**Success Rate**'}
    for strategy in strategies:
        values = []
        for asset in assets:
            result = results_dict[strategy][asset][period]
            if result is not None and metric == 'returns_pct':
                values.append(result[metric])
        if values:
            success_rate = np.sum(np.array(values) > 0) / len(values) * 100
            success_row[strategy] = f"**{success_rate:.1f}%**"
        else:
            success_row[strategy] = 'N/A'
    rows.append(success_row)

    df = pd.DataFrame(rows)
    return df


# =============================================================================
# MarkdownæŠ¥å‘Šç”Ÿæˆ
# =============================================================================

def generate_markdown_report(data, output_path='statistical_report.md'):
    """
    ç”Ÿæˆå®Œæ•´çš„Markdownç»Ÿè®¡æŠ¥å‘Š

    Args:
        data: å®éªŒç»“æœå­—å…¸
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„

    Returns:
        str: æŠ¥å‘Šå†…å®¹
    """
    results = data['results']
    metadata = data.get('metadata', {})

    # ç¡®å®šLLMç­–ç•¥åç§°
    llm_strategy = 'LLM_Adaptive' if 'LLM_Adaptive' in results else None
    if llm_strategy is None:
        print("âš ï¸ æœªæ‰¾åˆ°LLM_Adaptiveç­–ç•¥,æ— æ³•ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š")
        return None

    baselines = [s for s in results.keys() if s != llm_strategy]

    # å¼€å§‹ç”ŸæˆæŠ¥å‘Š
    lines = []
    lines.append("# åŸºçº¿å¯¹æ¯”å®éªŒ - ç»Ÿè®¡åˆ†ææŠ¥å‘Š\n")
    lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    lines.append(f"**å®éªŒæ—¶é—´**: {metadata.get('timestamp', 'N/A')}\n")
    lines.append(f"**ç­–ç•¥æ•°é‡**: {len(results)}\n")
    lines.append(f"**èµ„äº§æ•°é‡**: {len(list(results.values())[0])}\n")
    lines.append(f"**æ€»å›æµ‹æ•°**: {metadata.get('total_backtests', 'N/A')}\n")
    lines.append(f"**æˆåŠŸç‡**: {metadata.get('successful_backtests', 0)}/{metadata.get('total_backtests', 0)}\n")
    lines.append("\n---\n\n")

    # å¯¹æ¯ä¸ªæ—¶æœŸè¿›è¡Œåˆ†æ
    for period, period_name in [('training_period', 'è®­ç»ƒæœŸ'), ('testing_period', 'æµ‹è¯•æœŸ(æ ·æœ¬å¤–)')]:
        lines.append(f"## {period_name} åˆ†æ\n\n")

        # 1. æ”¶ç›Šç‡å¯¹æ¯”è¡¨
        lines.append(f"### 1. æ”¶ç›Šç‡å¯¹æ¯”è¡¨\n\n")
        table = generate_comparison_table(results, period, 'returns_pct')
        lines.append(table.to_markdown(index=False))
        lines.append("\n\n")

        # 2. Sharpe Ratioå¯¹æ¯”è¡¨
        lines.append(f"### 2. Sharpe Ratioå¯¹æ¯”è¡¨\n\n")
        table = generate_comparison_table(results, period, 'sharpe_ratio')
        lines.append(table.to_markdown(index=False))
        lines.append("\n\n")

        # 3. æœ€å¤§å›æ’¤å¯¹æ¯”è¡¨
        lines.append(f"### 3. æœ€å¤§å›æ’¤å¯¹æ¯”è¡¨\n\n")
        table = generate_comparison_table(results, period, 'max_drawdown_pct')
        lines.append(table.to_markdown(index=False))
        lines.append("\n\n")

        # 4. ç»Ÿè®¡æ£€éªŒ
        lines.append(f"### 4. ç»Ÿè®¡æ£€éªŒç»“æœ\n\n")

        for baseline in baselines:
            lines.append(f"#### {llm_strategy} vs {baseline}\n\n")

            test_result = paired_t_test(results, baseline, llm_strategy, period)

            if test_result is None:
                lines.append("âš ï¸ æ•°æ®ä¸è¶³,æ— æ³•è¿›è¡Œæ£€éªŒ\n\n")
                continue

            lines.append(f"**æ ·æœ¬é‡**: N = {test_result['sample_size']}\n\n")

            lines.append(f"**{baseline}**:\n")
            lines.append(f"- å¹³å‡æ”¶ç›Š: {test_result['baseline_mean']:+.2f}%\n")
            lines.append(f"- æˆåŠŸç‡: {test_result['baseline_success_rate']:.1f}%\n\n")

            lines.append(f"**{llm_strategy}**:\n")
            lines.append(f"- å¹³å‡æ”¶ç›Š: {test_result['ours_mean']:+.2f}%\n")
            lines.append(f"- æˆåŠŸç‡: {test_result['ours_success_rate']:.1f}%\n\n")

            lines.append(f"**å·®å¼‚**:\n")
            lines.append(f"- æ”¶ç›Šå·®è·: {test_result['mean_difference']:+.2f} percentage points\n")
            lines.append(f"- æˆåŠŸç‡æå‡: {test_result['ours_success_rate'] - test_result['baseline_success_rate']:+.1f}%\n\n")

            lines.append(f"**é…å¯¹tæ£€éªŒ**:\n")
            lines.append(f"- tç»Ÿè®¡é‡: {test_result['t_statistic']:.3f}\n")
            lines.append(f"- på€¼: {test_result['p_value']:.4f}\n")
            lines.append(f"- æ˜¾è‘—æ€§: {test_result['significance']} {test_result['sig_level']}\n\n")

            if test_result['p_value'] < 0.05:
                lines.append(f"âœ… **ç»“è®º**: {llm_strategy}æ˜¾è‘—ä¼˜äº{baseline} (p<0.05)\n\n")
            elif test_result['p_value'] < 0.10:
                lines.append(f"âš ï¸ **ç»“è®º**: {llm_strategy}è¾¹ç¼˜æ˜¾è‘—ä¼˜äº{baseline} (p<0.10)\n\n")
            else:
                lines.append(f"âŒ **ç»“è®º**: å·®å¼‚ä¸æ˜¾è‘— (p={test_result['p_value']:.3f})\n\n")

            lines.append("---\n\n")

        lines.append("\n")

    # æ€»ç»“
    lines.append("## æ€»ç»“\n\n")
    lines.append(f"æœ¬æŠ¥å‘ŠåŸºäº{metadata.get('total_backtests', 'N/A')}ä¸ªç‹¬ç«‹å›æµ‹å®éªŒ,")
    lines.append(f"å¯¹æ¯”äº†{len(results)}ä¸ªç­–ç•¥åœ¨{len(list(results.values())[0])}ä¸ªèµ„äº§ä¸Šçš„è¡¨ç°ã€‚\n\n")
    lines.append("è¯¦ç»†ç»Ÿè®¡æ£€éªŒç»“æœè§ä¸Šæ–‡å„èŠ‚ã€‚\n\n")
    lines.append("---\n\n")
    lines.append("*Report generated by statistical_analysis.py*\n")

    report_content = ''.join(lines)

    # ä¿å­˜æŠ¥å‘Š
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report_content)

    print(f"âœ… ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
    print(f"   æ–‡ä»¶å¤§å°: {Path(output_path).stat().st_size / 1024:.1f} KB")

    return report_content


# =============================================================================
# å¯è§†åŒ–å›¾è¡¨
# =============================================================================

def plot_comparison_charts(data, output_dir='charts'):
    """
    ç”Ÿæˆå¯¹æ¯”å›¾è¡¨

    Args:
        data: å®éªŒç»“æœå­—å…¸
        output_dir: å›¾è¡¨è¾“å‡ºç›®å½•

    Returns:
        list: ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    results = data['results']
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)

    chart_files = []

    # 1. è®­ç»ƒæœŸæ”¶ç›Šç‡å¯¹æ¯”æŸ±çŠ¶å›¾
    fig, ax = plt.subplots(figsize=(14, 8))

    strategies = list(results.keys())
    assets = list(results[strategies[0]].keys())

    returns_data = []
    for strategy in strategies:
        strategy_returns = []
        for asset in assets:
            result = results[strategy][asset]['training_period']
            if result is not None:
                strategy_returns.append(result['returns_pct'])
            else:
                strategy_returns.append(0)
        returns_data.append(strategy_returns)

    x = np.arange(len(assets))
    width = 0.2
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']

    for i, (strategy, returns) in enumerate(zip(strategies, returns_data)):
        offset = width * (i - len(strategies)/2 + 0.5)
        ax.bar(x + offset, returns, width, label=strategy, color=colors[i % len(colors)])

    ax.set_xlabel('Assets', fontsize=12)
    ax.set_ylabel('Returns (%)', fontsize=12)
    ax.set_title('Training Period Returns Comparison', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels([a.split('_')[0] for a in assets], rotation=45, ha='right')
    ax.legend(loc='upper left')
    ax.axhline(y=0, color='black', linestyle='--', linewidth=0.5)
    ax.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    chart_path = output_dir / 'training_returns_comparison.png'
    plt.savefig(chart_path, dpi=300, bbox_inches='tight')
    plt.close()
    chart_files.append(str(chart_path))
    print(f"âœ… å›¾è¡¨å·²ä¿å­˜: {chart_path}")

    # 2. æµ‹è¯•æœŸæ”¶ç›Šç‡å¯¹æ¯”æŸ±çŠ¶å›¾
    fig, ax = plt.subplots(figsize=(14, 8))

    returns_data_test = []
    for strategy in strategies:
        strategy_returns = []
        for asset in assets:
            result = results[strategy][asset]['testing_period']
            if result is not None:
                strategy_returns.append(result['returns_pct'])
            else:
                strategy_returns.append(0)
        returns_data_test.append(strategy_returns)

    for i, (strategy, returns) in enumerate(zip(strategies, returns_data_test)):
        offset = width * (i - len(strategies)/2 + 0.5)
        ax.bar(x + offset, returns, width, label=strategy, color=colors[i % len(colors)])

    ax.set_xlabel('Assets', fontsize=12)
    ax.set_ylabel('Returns (%)', fontsize=12)
    ax.set_title('Testing Period Returns Comparison (Out-of-Sample)', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels([a.split('_')[0] for a in assets], rotation=45, ha='right')
    ax.legend(loc='upper left')
    ax.axhline(y=0, color='black', linestyle='--', linewidth=0.5)
    ax.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    chart_path = output_dir / 'testing_returns_comparison.png'
    plt.savefig(chart_path, dpi=300, bbox_inches='tight')
    plt.close()
    chart_files.append(str(chart_path))
    print(f"âœ… å›¾è¡¨å·²ä¿å­˜: {chart_path}")

    # 3. ç®±çº¿å›¾ (è®­ç»ƒæœŸ)
    fig, ax = plt.subplots(figsize=(10, 6))

    box_data = []
    box_labels = []
    for strategy in strategies:
        strategy_returns = []
        for asset in assets:
            result = results[strategy][asset]['training_period']
            if result is not None:
                strategy_returns.append(result['returns_pct'])
        if strategy_returns:
            box_data.append(strategy_returns)
            box_labels.append(strategy)

    bp = ax.boxplot(box_data, labels=box_labels, patch_artist=True,
                     showmeans=True, meanline=True)

    for patch, color in zip(bp['boxes'], colors):
        patch.set_facecolor(color)
        patch.set_alpha(0.6)

    ax.set_ylabel('Returns (%)', fontsize=12)
    ax.set_title('Training Period Returns Distribution', fontsize=14, fontweight='bold')
    ax.axhline(y=0, color='red', linestyle='--', linewidth=1, alpha=0.5)
    ax.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    chart_path = output_dir / 'training_returns_boxplot.png'
    plt.savefig(chart_path, dpi=300, bbox_inches='tight')
    plt.close()
    chart_files.append(str(chart_path))
    print(f"âœ… å›¾è¡¨å·²ä¿å­˜: {chart_path}")

    return chart_files


# =============================================================================
# ä¸»ç¨‹åºå…¥å£
# =============================================================================

def main():
    """å®Œæ•´ç»Ÿè®¡åˆ†ææµç¨‹"""
    import argparse

    parser = argparse.ArgumentParser(description='åŸºçº¿å¯¹æ¯”å®éªŒç»Ÿè®¡åˆ†æ')
    parser.add_argument('--input', type=str,
                        default='/root/autodl-tmp/outputs/baseline_comparison_results.json',
                        help='è¾“å…¥JSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str,
                        default='/root/autodl-tmp/outputs/statistical_report.md',
                        help='è¾“å‡ºMarkdownæŠ¥å‘Šè·¯å¾„')
    parser.add_argument('--charts-dir', type=str,
                        default='/root/autodl-tmp/outputs/charts',
                        help='å›¾è¡¨è¾“å‡ºç›®å½•')
    parser.add_argument('--no-charts', action='store_true',
                        help='ä¸ç”Ÿæˆå›¾è¡¨ (ä»…æŠ¥å‘Š)')

    args = parser.parse_args()

    print("=" * 80)
    print("åŸºçº¿å¯¹æ¯”å®éªŒ - ç»Ÿè®¡åˆ†æ")
    print("=" * 80)

    # 1. åŠ è½½æ•°æ®
    print("\nğŸ“‚ åŠ è½½å®éªŒç»“æœ...")
    data = load_results(args.input)

    # 2. ç”ŸæˆMarkdownæŠ¥å‘Š
    print("\nğŸ“Š ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š...")
    report = generate_markdown_report(data, args.output)

    if report is None:
        print("âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
        return

    # 3. ç”Ÿæˆå›¾è¡¨
    if not args.no_charts:
        print("\nğŸ“ˆ ç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
        try:
            chart_files = plot_comparison_charts(data, args.charts_dir)
            print(f"\nâœ… å…±ç”Ÿæˆ{len(chart_files)}ä¸ªå›¾è¡¨")
        except Exception as e:
            print(f"âš ï¸ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    print("\n" + "=" * 80)
    print("åˆ†æå®Œæˆ!")
    print("=" * 80)
    print(f"ğŸ“„ ç»Ÿè®¡æŠ¥å‘Š: {args.output}")
    if not args.no_charts:
        print(f"ğŸ“Š å›¾è¡¨ç›®å½•: {args.charts_dir}")
    print("=" * 80)


if __name__ == '__main__':
    main()
